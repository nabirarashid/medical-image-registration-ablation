{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# ====================================================================\n",
        "# CREATE AND SAVE TRAIN/TEST SPLIT - RUN THIS ONCE\n",
        "# ====================================================================\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "\n",
        "# Mount Google Drive\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    if not os.path.exists('/content/drive'):\n",
        "        drive.mount('/content/drive')\n",
        "    print(\"✅ Google Drive mounted\")\n",
        "except:\n",
        "    print(\"⚠️ Not in Colab or Drive already mounted\")\n",
        "\n",
        "# Define your Google Drive path\n",
        "GDRIVE_PROJECT_PATH = '/content/drive/MyDrive/segmentation-project'\n",
        "\n",
        "def save_train_test_split(data_file_path, test_size=0.3, random_state=42):\n",
        "    \"\"\"Create and save train/test split to Google Drive\"\"\"\n",
        "\n",
        "    # Create project directory\n",
        "    os.makedirs(GDRIVE_PROJECT_PATH, exist_ok=True)\n",
        "\n",
        "    # Load all files and update paths\n",
        "    try:\n",
        "        with open(data_file_path, 'r') as f:\n",
        "            original_files = [line.strip() for line in f.readlines() if line.strip()]\n",
        "\n",
        "        # Update paths from old format to new format\n",
        "        all_files = [file.replace('neurite-oasis.v1.0/', 'segmentation_data/') for file in original_files]\n",
        "\n",
        "        print(f\"Loaded {len(all_files)} files from {data_file_path}\")\n",
        "        print(f\"📝 Updated paths: neurite-oasis.v1.0/ → segmentation_data/\")\n",
        "    except FileNotFoundError:\n",
        "        print(f\"❌ {data_file_path} not found!\")\n",
        "        return None, None\n",
        "\n",
        "    # Set random seed and shuffle\n",
        "    np.random.seed(random_state)\n",
        "    shuffled_files = np.random.permutation(all_files)\n",
        "\n",
        "    # Calculate split\n",
        "    n_total = len(shuffled_files)\n",
        "    n_test = min(20, max(5, int(n_total * test_size)))\n",
        "    n_train = n_total - n_test\n",
        "\n",
        "    # Split the data\n",
        "    test_files = shuffled_files[:n_test]\n",
        "    train_files = shuffled_files[n_test:]\n",
        "\n",
        "    print(f\"📊 Dataset split: {n_total} total → {n_train} train, {n_test} test\")\n",
        "\n",
        "    # Save to Google Drive\n",
        "    train_split_path = os.path.join(GDRIVE_PROJECT_PATH, 'train_split.txt')\n",
        "    test_split_path = os.path.join(GDRIVE_PROJECT_PATH, 'test_split.txt')\n",
        "\n",
        "    with open(train_split_path, 'w') as f:\n",
        "        f.write('\\n'.join(train_files))\n",
        "\n",
        "    with open(test_split_path, 'w') as f:\n",
        "        f.write('\\n'.join(test_files))\n",
        "\n",
        "    # Save metadata\n",
        "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "    metadata_path = os.path.join(GDRIVE_PROJECT_PATH, 'split_metadata.txt')\n",
        "    with open(metadata_path, 'w') as f:\n",
        "        f.write(f\"Split created: {timestamp}\\n\")\n",
        "        f.write(f\"Random seed: {random_state}\\n\")\n",
        "        f.write(f\"Test size: {test_size}\\n\")\n",
        "        f.write(f\"Total files: {n_total}\\n\")\n",
        "        f.write(f\"Train files: {n_train}\\n\")\n",
        "        f.write(f\"Test files: {n_test}\\n\")\n",
        "        f.write(f\"Original data file: {data_file_path}\\n\")\n",
        "\n",
        "    print(f\"✅ Train split saved: {train_split_path}\")\n",
        "    print(f\"✅ Test split saved: {test_split_path}\")\n",
        "    print(f\"✅ Metadata saved: {metadata_path}\")\n",
        "\n",
        "    return train_files, test_files"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sUSyL_kfgwRj",
        "outputId": "26305855-af9a-4e4f-9e4e-72a48c3740fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Google Drive mounted\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ====================================================================\n",
        "# RUN THE SPLIT - MODIFY THESE PATHS AS NEEDED\n",
        "# ====================================================================\n",
        "\n",
        "# Your data file path\n",
        "data_file_path = 'train_npy_copy.txt'\n",
        "\n",
        "# Create and save the split\n",
        "print(\"🔄 Creating train/test split...\")\n",
        "train_files, test_files = save_train_test_split(\n",
        "    data_file_path=data_file_path,\n",
        "    test_size=0.3,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "if train_files is not None:\n",
        "    print(\"🎉 SPLIT CREATED AND SAVED SUCCESSFULLY!\")\n",
        "    print(f\"📁 Files saved in: {GDRIVE_PROJECT_PATH}\")\n",
        "    print(\"🔒 Your test set is now locked for final evaluation only!\")\n",
        "    print(\"\")\n",
        "    print(\"Next steps:\")\n",
        "    print(\"1. Use train_split.txt for training your model\")\n",
        "    print(\"2. Use test_split.txt ONLY for final evaluation\")\n",
        "else:\n",
        "    print(\"❌ Split creation failed!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-oFaGPLcgyuA",
        "outputId": "7756d16a-1657-466d-831c-8fce613b377f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔄 Creating train/test split...\n",
            "Loaded 414 files from train_npy_copy.txt\n",
            "📝 Updated paths: neurite-oasis.v1.0/ → segmentation_data/\n",
            "📊 Dataset split: 414 total → 394 train, 20 test\n",
            "✅ Train split saved: /content/drive/MyDrive/segmentation-project/train_split.txt\n",
            "✅ Test split saved: /content/drive/MyDrive/segmentation-project/test_split.txt\n",
            "✅ Metadata saved: /content/drive/MyDrive/segmentation-project/split_metadata.txt\n",
            "🎉 SPLIT CREATED AND SAVED SUCCESSFULLY!\n",
            "📁 Files saved in: /content/drive/MyDrive/segmentation-project\n",
            "🔒 Your test set is now locked for final evaluation only!\n",
            "\n",
            "Next steps:\n",
            "1. Use train_split.txt for training your model\n",
            "2. Use test_split.txt ONLY for final evaluation\n"
          ]
        }
      ]
    }
  ]
}